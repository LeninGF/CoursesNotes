
#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil expand-links:t f:t
#+options: inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+title: Inteligencia Artificial Generativa
#+date: 2024-10-02
#+author: Lenin G. Falconí
#+email: lenin.falconi@epn.edu.ec
#+language: es
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 27.1 (Org mode 9.7.5)
#+cite_export:

#+begin_comment
* Lecture
** Questions and keywords
** Notes
** Summary
#+end_comment

* Modelamiento Generativo 2024-10-02 
** Questions and keywords
- modelo generativo :: produce datos nuevos similares al dataset de
  entrenamiento. son esencialmente probabilisticos.
- modelos discriminativos :: son modelos que clasifican (supervisado,
  no supervisado y por refuerzo)
- modelos generativos condicionales :: $P(\mathbf{x}|y)$
- GAN :: es un modelo generativo (herramienta) mas un discriminativo
  (lupa). El generativo quiere engañar al discriminativo. El modelo
  discriminativo no puede distinguir el dato real y el falso. Aparecen
  en 2014.
- AGI inteligencia artificial general :: requiere conocimiento,
  razonamiento, pensamiento creativo, vision, lenguaje. debe
  confundirse con la humana
- no entiendo como dice que los modelos generativo y discrimintivo "share notes" :: al
  parecer la nota que se comparte es el valor que el discriminador
  obtiene indicando si el fake generado es mejor
- cuanto es un zetabyte :: 
- ¿puede usar un modelo generativo en el tiempo? ::
- transformers ::
- aprendizaje por refuerzo con realimetntación humana :: aprovecha el
  feedback humano para mejorar
- RLHF :: requiere datos de entrenamiento de humanos
- transformers :: atención, sensitiva contexto
- gan ::  requiere competencia de modelos
** Notes
- Modelo discrimintavio estima $P(y|x)$
  - Predecir el clima
  - categorizar libros
  - categorizar imagenes
- Modelo discriminativo tiene una probabilidad de que la predicción
  corresponda a una clase.
- El modelo generativo estima $P(x)$ pero hay la opción
  condicional. E.g. hacer un vangoh pero nocturno
- Existen varias aplicaciones en redes, en graficos, juegos,
  marketing, educativas, médicas, industriales, chatbots
- Existen diferentes juegos de entrada y salida para la I. Generativa:
  - prompt a texto
  - promt a imagen y
  - de imagen a imagen
- Tiene generalización y particularidad
- Los GANs es una combinacion entre modelo generativo y discriminativo
- Inteligencia artificial generativa puede:
  - escribir codigo para una website
  - contestar a un cliente preguntas de servicio
  - generar una imagen
- Inteligencia artificial general: hacer trabajos humanos 100%. Esto es discutible.
- Factores que facilitan la IA generativa son:
  - aumento poder computacional
  - grandes cantidades de datos
  - competencias geopoliticas y entre desarrolladores
  - herramientas y modelos disponibles (comunidad)
- transformers
** Summary
Los modelos generativos son aquellos modelos de /machine learning/ que
entrenan un modelo capaz de producir nuevos datos similares a los de
un conjunto de datos. Un modelo generativo es esencialmente
probabilístico ya que se desea poder obtener diferentes variaciones
del resultado final antes que el mismo resultado cada vez. Estos
modelos no requieren que el dataset tenga etiquetas. Trata de modelar
la probabilidad de observar un objeto $\mathbf{x}$

Un ejemplo de modelo discriminativo son los clasificadores. Pues,
éstos tratan de predecir una etiqueta. Es decir trata de modelar la
probabilidad de una etiqueta $y$ dada una observación $\mathbf{x}$

- Modelo discriminativo :: $P(y|\mathbf{x})$
- Modelo Generativo :: $P(\mathbf{x})$
- Modelo Generativo Condicional :: es la probabilidad de ver una
  observación $\mathbf{x}$ con una etiqueta $y$ específica i.e. $P(\mathbf{x}|y)$

* 2024-10-07 Entrenamiento y Evaluación de Modelos
** Questions and keywords
- stable diffusion:: ¿que es?
- personally identifiable information :: ??
- las ideas sobre transferlearning sobre el tamaño del dataset y el
  orden en que se ejecutan o son nuevas o son equivocadas no las
  conozco y debo averiguar. Por ejemplo se afirmó que fine tuning se
  hace luego de transfer learning
- espacio latente :: está relacionado al concepto de embeddings
- métricas modelos generativos:
  - inception score IS (img) :: evalua imagenes eneradas segin la
    probabilidad de pertenecer a distintas categorías. Quería generar
    gatos son gatos o no.
  - frechet inception distance FID (img) :: mide distancia entre las
    distribuciones de las imágenes relates y las generadas.
  - bleu (texto) :: similitud del texto generado y el de referencia
  - Rouge (texto) :: similitud del texto generado y el de referencia
- injusticia entre comparar lo que la máquina hace con respecto a lo
  que hace el humano
- gold standard :: evaluación inteligente realizada por humanos u otras IA
- test de turing :: aplica como medida en IA generativa?
** Notes
- recopilación de datos:
  - grandes volumenes
  - datos diversos
  - datos ricos
  - requiere pre procesamiento
- preprocesamiento es una tarea adecuada
- privacidad y seguridad :: los datos han de cumplir con PII con su
  respectiva controles de seguridad.
*** Entrenamimento de modelos
- el hardware a utilizar
- el tiempo requerido se refleja en el tamaño del dataset, la
  complejidad del modelo y el número de rondas de entrenamient
- el costo
- técnicas avanzadas de entrenamiento:
  - Transfer learning :: transfiere conocimiento de una tarea a otra
  - fine tuning :: es un tipo de transfer learning para un dataset más
    pequeño. se usa luego de transfer learning
  - human in the loop :: ajusta las respuestas con lo que el humano da feedback
  - embeddings :: representaciones únicas de entidades de
    datos. representan la información de manera compacta
*** Evaluación de modelos:
- en modelos generativos cómo se evalúa su desempeño
- evaluación discriminativa :: puede usar precisión/accuracy. Pero no
  son aplicables para medir la creatividad del modelo
- en general se mide el progreso del modelo en el tiempo
- criterios de comparación entre diferentes versiones del modelo
- comparación del modelo con el rendimiento humano
- hay metricas específicas par atexto, imagen o audio
- la comparación con el rendimiento humano. comparación de
  habilidades. se puede suponer que es una comparación injusta. por
  ejmplo, comparar si el producto generado por la IA debe ser
  comparado con el trabajo humano.
- una relativa amenaza sobre las habilitades humanas
** TODO Métricas de Evaluación de Imagenes generadas por GAN (FID y LPIPS) [66%]
- [X] Investigación de FID
- [X] Investigación de LPIPS
- [ ] Generar documento
** Summary
* 2024-10-09 Exposición métricas y  Representación del Conocimiento
** Questions and keywords
- n-grams ::
- BLEU :: cómo es y cómo funciona
- ROUGE :: cómo varía cuando es alto o bajo. Cuando es 1 son idénticos si es menor, difiere.
- ¿se verificó el cómputo de ROUGE y METEOR? ::
- decoder :: 
- encoder ::
- hay algun limite para el tamaño del espacio latente? ::
- espacio latente ::
- que tan complicado es generar una fake imagen medica ::
- que tan raro es hacer una genreación en el tiempo ::
- cómo funciona pytorch a nivel de autoencodres, vaes ::
- se puede establecer una relacion entre la entropia de shannon y el espacio latente ::
- cómo se llama el paper de Jona :: un espacio latente independiente
  del tipo de dato. es sobre representación platónica. asumen que es
  parte de la realidad. Mientras es más completo el modelo converge el
  tema de lenguaje y de imagen para generar una imagen de manzana y
  viceversa. The Platonic Representation Hypothesis
- modelado paramétrico :: 
- likelihood o verosimilitud :: identificar parámetros que maximicen la probabilidad
- MLE :: máxima verosimilitud
- densidad tractable :: se define de antemano: normal bernoulli
- densidad aproximada :: depende de los datos
- que se debe hacer en la tarea? :: resumen analisis discusion?
** Notes
*** Exposicion
- METEOR parece ser superior a BLEU
- Valores altos de METEOR implica una alta similitud del texto generado con el original
- METEOR parece ser superior que ROUGE 
*** Represetacion del conocimiento
- Reducir el espacio de alta dimensionalidad a un espacio latente con menores dimensiones
- el espacio latente aprende representaciones simplificadas de datos
- los nuevos datos son variar coordenadas en el espacio latente
- este movimiento en el espacio latente podría por ejemplo afectar las
  expresiones faciales de un rostro si es una ia generativa de rostros
  o avegentar o rejuvenecer
- el espacio latente permite explorar **relaciones abstractas** entre los datos
- un modelado paramétrico es una familia de distribuciones de probabilidad
- la verosimilitud se calcula con el logaritmo para tener una suma de
  los logaritmos de las probabilidad
- MLE selecciona que valores de parámetros $\theta$ que maximizan la verosimilitud
- hay varios approaches para el modelado de la función de
  densidad. esto se conoce como taxonomía
** Summary
** TODO Tarea [100%]
- [X] leer el paper del aula virtual. Presentar conclusiones.
* 2024-10-14 Capitulo 2 Redes Neuronales
** Questions and keywords
- redes neuronales ::
- axones :: 
- dendritas ::
- funciones de activación ::
- relu :: no comprendo bien la fórmula de la relu
- revisar ajuste de pesos del perceptron ::
- gradient descent ::
- stochastic gradient descent ::
- minibatch ::
- red neuronal se puede aplicar en aprendizaje por refuerzo :: las
  salidas son acciones, pero que son las entradas
- algoritmo de back propagation ::
- ¿se menciona el problema del gradiente cuando las capas son muy grandes :: el
  gradiente desaparece por la profundidad
- deep neural netowrks :: tiene 3 o más capas ocultas
- 0 :: negro
- 255 :: blanco
- kernel :: ??
- lo que no mencionan es que los valores de la convolución también se aprenden 
** Notes
*** Exposición Jona audio
- FAD :: Freched Audio Distance. Similar al FID pero con audio.
  - utiliza todo el dataset 
- Signal to noise ratio :: cuando el valor es más alto la señal es más
  nitida. Es el cociente de la Potencia de la señal dividido para la Potencia del ruido. Se toma logaritmo
  - es fácil de calcular
  - es estandard
  - sus dificultades que no captura todas las caracteristicas perceptuales el audio
*** Capítulo 2 redes neuronales artificiales
- son una analogía de las redes nueronales biológicas
- el perceptron es usar una recta para separar las clases (boundary regions)
- $h(x_1,x_2)= g(w_0+w_1x_1+w_2x_2)$
- funcioes de activacion:
  - step function
  - sigmoid
  - relu
- aplicaciones son logica binaria como la compuerta lógica OR en función de la tabla de verdad
- algoritmo de descenso del gradiente. Sugiero revisar cómo opera el
  algoritmo para hacer el ajuste de pesos. Se parte aleatoriamente y se usa la gradiente
- el perceptron separa las clases en forma lineal
- las rdes neuronale multicapas son para problemas que no son
  linealmente dependientes. Para resolver en casos que la región a
  separar no es lineal. Ejemplo son círculos concéntricos
- el algoritmo de backpropagation se usa cuando existen varias capas.
- Overfitting sobre ajuste de los datos :: la red presenta una metrica
  de evaluacion con un muy buen score en los datos de entrenamiento
  pero pobre en los datos de testeo
- Dropout :: desactiva neuronas aleatoriamente durante el entrenamiento
- Frameworks de DeepLearning:
  - Pytorch
  - Tensorflow [[https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.64829&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false][tensorflow-playground]]
*** Computer vision
- imagen :: matriz de pixels con valores en tres capas RGB en un rango de 0 a 255
- convolución :: filtro que usa un kernel que extrae características
  de una región de la imágen. algo parecido a un detector de bordes
- la convolucion permite disminuir el tamaño de la matriz de la imagen
  y obtener valores segun el conocimiento local
- el detector de borde:
  |----+----+-----|
  | -1 | -1 |  -1 |
  |----+----+-----|
  | -1 |  8 |  -1 |
  |----+----+-----|
  | -1 | -1 | - 1 |
  |----+----+-----|
- pooling :: obtiene un valor del resultado de la convolucional e.g. el max-pooling
- flattening ::
- los pasos de convolucion y pooling se repitenn varias
  veces. mientras estoy raliezando convolution and pooling estoy en
  low level features, es decir reconociendo curvas y bordes y al final
  de la red ya tengo una operación de alto nivel que sería reconocer objetos.
- redes neuronales convolucionales sirven para reconcoer objetos en imagenes 
** Summary
* 2024-10-16 Redes ConvNet VGG
** Questions and keywords
- embeddings ::
- en verdad se puede usar una red convolucional en series de tiempo? ::
- segun la profesora que no va redes neuronales recurrentes en series de tiempo?? :: 
- espectograma ::
- bloques residuales :: 
** Notes
*** CNN
- importante la invarianza a la traslación
- las convnets son versatiles par usar modelos pre-entrenados
- la primeras capas detectan caracteristicas simples como bordes
- el modelo de redes neuronales convolucionales pueden adaptarse a
  otros problemas porque reconocen patrones
- invarianza a la posición
- procesan datos en secuencia???
- procesan datos en paralelo???
- modelos pre-entrenados:
  - vgg16:
    - Desarrollado en Oxford
    - Uso repetido de convolucionales con filtros de $3 \times 3$
    - 16 capas : 13 conv + 3 densas
    - capas de max pooling
    - el vector de caracteristica 4096
  - resnet50
  - inceptionv3
*** Series de tiempo
- determinar coomo funcionan las convnets en series de tiempo
*** Speech recognition
- ????
  
** Summary
** TODO Tareas
- [ ] consulta sobre embeddings aula virtual
  - [ ] word2vec
  - [ ] glove
  - [ ] bert
* 2024-10-21 Redes Resneet
** Questions and keywords
- bloque residual::
- revisar el ejemplo de calculo en los slides
- ¿permite el bloque residual aumentar el número de capas de una red?
- en los slides se menciona que fine tuning es reentrenar por completo
  pero partiendo de los pesos pre-entrenados
- ¿resnet 150 dice que tiene 177 capas?
- congelamiento de capas :: sólo entrena las últimas capas (extractor de características)
** Notes
- La red Resent aprende la diferencia entre la función sin activación y la entrada $f(Wx+b)-x$
- Ejemplo x=2, W=0.5 y b=1. Considere Relu $f(z)=max(0,z)$
- evita que la gradiente se desvanezca al utilizar el residuo
- la neurona residual puede mantener el valor original sin cambios (salida cercana a la entrada)
- asegura que fluya el gradiente
- Ejemplos de redes resnet es ResNet50, ResNet152
- Se puede usar para hacer fine-tuning
- se puede usar en freeze layers
- Resnet son utilizadas en aplicacinoes de visión por computador (e.g. detección de objetos)
- Fine - Tuning:
  - Tiene más probabilidad de Overfitting si los datos son pocos
  - es adecuado si se tiene un conjunto grande de datos
- Layer Freeze:
  - para conjuntos de datos de pocos samples
- Ejercicio 1 clasificación de imágenes con freeze layers
** Summary
* 2024-10-23 GoogleNet e Inception
** Questions and keywords
- inception bloque ::
- hierarchical sofmax :: se uso en word2vec pero podriamos usar para
  un pruning?
- word2vec utiliza CBOW(continuos bag of words) ::
- one-hot vector ::
- skip-gram :: predice las palabras de contexto dadas una palabra
- word2vec se entrena para cada corpus o ya está entrenado? ::
- cómo usar word2vec en español ::
- co-ocurrence matrix ::
- context window ::
- glove se usa en calculo de similitud :: 
** Notes
*** GoogleNet Inception
- los bloques inception rducen el costo computacional
*** Ejercicio
- consiste en modificar la estructura del Inception
- se usa el cifar 10
*** Exposiciones - word2vec
- word2vec permite la matematizacion del lenguaje
- usa una red neuronal de una capa
- crea dos matrices principales
- permite hacer analogías de palabras:
  Rey - Hombre + Mujer = Reina
- el coseno de similitud permite saber que las palabras son
  similares. esto permite verificar que los embeddings funciona
- contexto limitado
- capa de entrada: palabras actual
- capa oculta son las neuronas de los embeddings
- tiene dos arquitecturas CBOW y skip-gram
- el objetivo de CBOW es maximizar la probabilidad de predecir la
  palabra objetivo dada las palabras de contexto
- skip-gram:
  - inpt: palabra
  - capa oculta: 
  - salida: es el embedding resultante
*** GLoVe
- Stanford
- trabaja relaciones semanticas reina es a rey y sintácticas big a bigger
- su nucleo es una matriz de co-ocurrencia
- la matriz de co-ocurrencia cuenta las palabras en una ventana de contexto pares
- lo malo es que requiere una gran cantidad de datos  para entrenar
- costoso  para matrices grandes
** Summary

** 2024-10-28 YOLO
** Questions and keywords
- YOLO ::
- object detection :: identificar y localizar objetos en una imagen/escena
- mAP :: mean average precision
- idea :: combinar yolo y redes de grafos para poder explicar escenas
  es mejor que transformers que combinen texto e imagen
** Notes
- Es un modelo pre-entrenado
- detecta uno o múltiples objetos usando bounding boxes
- Ventajas: preciso, abierto, rápido
- 91 fps para YOLO high
*** Yolo v1
- 24 capas, 4 max pooling y 2 capas
- input 448x448
- usa Relu a las capas intermedias
- capa de salida usa activación lineal para obtener coordenadas
- usa batch normalization
- usa:
  - bloques residuales: divide la imagen en un acuadricula y predice
    la probabilidad de un objeto en las celdas
  - regresion de cajas delimitadores: poner las coordenadas de los objetos
- se queda con la caja que tenga mayor precision del objeto
*** Batch Normalization
- ttoma por bloques los datos y para que tengan una media cercana a 0 y varianza cercana a 1
- es normalizar los valores
- evita el vanishing gradient y el exploding gradient
- reduce dependencia d einicio de pesos
- reduce sobre-ajuste
- limita la variación del gradiente
*** Métrica IoU
- Es el area de intersección sobre area de unión
- Mientras más cercano a 1 excelente superposición
- cercano a 0, no hay objeto
** Summary
** TODO [%]
- app para celular, usar version 5
- checar la aplicacion de detección de melanoma con YOLO
- Análisis papers version 3 y 4 (2 papers). Son papers de Arxiv
- Prueba el proximo miercoles

* 2024-10-30 RNN
** Questions and keywords
- RNN ::
- consultar la clasificación de muchos a uno y muchos a muchos en RNN
- encoder :: representar la información en un embedding
- decoder :: reconstruye la información de salida
- unigram ::
- bigram ::
- trigram ::
- token ::
- preguntar a jonathan de donde saco la funcion print examples 
** Notes
- retener información de los datos anteriores
- son redes que trabajen en una secuencia de datos
- retiene información de palabras anteriores
- este diseño ayuda a comprender el contexto
- RNN tiene una estructura d emuchos a uno
*** Modelos de secuencia a secuencia
- son utiles en procesameinto de lenguaje natural
- en computer vision para comprender escenas e.g. en vídeo
- Muchos a uno :: una sola salida por ejemplo un clasificador de sentimentos
- muchos a muchos:
  - Generador de Texto
  - Traductor de Texto: formado por un *encoder* y un *decoder*
  - Modelos de Lenguaje: generan texto. Predeice la siguiente palabra. 
** Ejercicio
Comparar el número de parámetros de una ANN wrt RNN:
1. vocabulario de 10000
2. usan una capa densa de 256 unidades
3. Usar summary para ver la arquitectura y el número de parámetros
4. embedding de 64 para RNN
[[https://colab.research.google.com/drive/1Rid1ImfCW1UqvslNzztA0lUae-VK2qT8?hl=es#scrollTo=xPYsGMEb5sdU][colab-compare-rnn-y-ann]]
*** Modelos de lenguaje
- Buscan predecir la probabilidad de secuencias de palabras se usan: unigram, bigram y trigram
- En general es calcular la probabilidad de la palabra actual en función de las anterioresl.
- skip-gram: calcula probabilidad de palabras cercanas. tantos anteriores y posteriores
- las redes neuronales usan /Softmax/
*** Capa de embedding
- recibe secuencia de tokens que representan el texto a procesar
- se convierte las palabras en indices o vectores
- la capa converte a cada token en un vector de números que captura relaciones semánticas
- palabras con significados similares tendran representaciones vectoriales cercanas
*** Capa RNN
- son celdas que procesan la secuencia
- permiten al modelo recordar información anterior
- la salida es una probabilidad o una rpedicción de clases
*** Diccionarios de vocabulario
1. obtener palabras únicas
2. se crea un diccionario donde cada palabra es la clave y el indice es el valor
3. se puede obtener el diccionario inverso
*** Ejercicio 1
construir un diccinario por palabras y por indices a partir de las sheldon_quotes
#+begin_src python :results output :exports both :session
sheldon_quotes = ["You're afraid of insects and women, Ladybugs must render you catatonic.",
                  'Scissors cuts paper, paper covers rock, rock crushes lizard, lizard poisons Spock, Spock smashes scissors, scissors decapitates lizard, lizard eats paper, paper disproves Spock, Spock vaporizes rock, and as it always has, rock crushes scissors.']
all_words = ''.join(sheldon_quotes).split(' ')
print(all_words)
#+end_src

#+RESULTS:
: ["You're", 'afraid', 'of', 'insects', 'and', 'women,', 'Ladybugs', 'must', 'render', 'you', 'catatonic.Scissors', 'cuts', 'paper,', 'paper', 'covers', 'rock,', 'rock', 'crushes', 'lizard,', 'lizard', 'poisons', 'Spock,', 'Spock', 'smashes', 'scissors,', 'scissors', 'decapitates', 'lizard,', 'lizard', 'eats', 'paper,', 'paper', 'disproves', 'Spock,', 'Spock', 'vaporizes', 'rock,', 'and', 'as', 'it', 'always', 'has,', 'rock', 'crushes', 'scissors.']

#+begin_src python :results output :exports both :session
unique_words = list(set(all_words))
print(len(unique_words))
#+end_src

#+RESULTS:
: 35

#+begin_src python :results output :exports both :session
index_to_word = {i:wd for i, wd in enumerate(sorted(unique_words))}
print(index_to_word.items())
#+end_src

#+RESULTS:
: dict_items([(0, 'Ladybugs'), (1, 'Spock'), (2, 'Spock,'), (3, "You're"), (4, 'afraid'), (5, 'always'), (6, 'and'), (7, 'as'), (8, 'catatonic.Scissors'), (9, 'covers'), (10, 'crushes'), (11, 'cuts'), (12, 'decapitates'), (13, 'disproves'), (14, 'eats'), (15, 'has,'), (16, 'insects'), (17, 'it'), (18, 'lizard'), (19, 'lizard,'), (20, 'must'), (21, 'of'), (22, 'paper'), (23, 'paper,'), (24, 'poisons'), (25, 'render'), (26, 'rock'), (27, 'rock,'), (28, 'scissors'), (29, 'scissors,'), (30, 'scissors.'), (31, 'smashes'), (32, 'vaporizes'), (33, 'women,'), (34, 'you')])

#+begin_src python :results output :exports both :session
word_to_index = {wd:i for i, wd in enumerate(sorted(unique_words))}
print(word_to_index.items())
#+end_src

#+RESULTS:
: dict_items([('Ladybugs', 0), ('Spock', 1), ('Spock,', 2), ("You're", 3), ('afraid', 4), ('always', 5), ('and', 6), ('as', 7), ('catatonic.Scissors', 8), ('covers', 9), ('crushes', 10), ('cuts', 11), ('decapitates', 12), ('disproves', 13), ('eats', 14), ('has,', 15), ('insects', 16), ('it', 17), ('lizard', 18), ('lizard,', 19), ('must', 20), ('of', 21), ('paper', 22), ('paper,', 23), ('poisons', 24), ('render', 25), ('rock', 26), ('rock,', 27), ('scissors', 28), ('scissors,', 29), ('scissors.', 30), ('smashes', 31), ('vaporizes', 32), ('women,', 33), ('you', 34)])
*** Ejercicio 2
Dividir los textos en caracteres para poder hacer generación de texto
mediante dos secuencias.

Se requeire una funcion ~print_examples~ para que se pueda ver como se transforman los datos
#+begin_src python :results output :exports both :session
step = 2
chars_window = 10
next_chars = []
sentences = []
all_char = all_words
for i in range(0, len(all_char) - chars_window,step):
    sentences.append(all_char[i:i+chars_window])
    next_chars.append(all_char[i+chars_window])
print(next_chars)
#+end_src

#+RESULTS:
: ['catatonic.Scissors', 'paper,', 'covers', 'rock', 'lizard,', 'poisons', 'Spock', 'scissors,', 'decapitates', 'lizard', 'paper,', 'disproves', 'Spock', 'rock,', 'as', 'always', 'rock', 'scissors.']
*** Keras
- el padding permite colocar el vector de un mismo tamaño. Es decir si
  cada uno de los documentos del corpus no tienen la misma cantdiad de
  palabras padding equilibra esto.
[[https://colab.research.google.com/drive/1g7p2hjIwdAswOuKua0OB_37mLSm09XXs?hl=es#scrollTo=-kY3hT8WOWLC][colab-rnn-keras-problema3]]
** Summary
* 2024-11-06 RNN y LST
** Questions and keywords
- forward propagation ::
- vanishing gradeint :: gradientes con valores cercanos a 0
- simple rnn ::
- que pasa si se diseña una RNN que no comparta los pesos $W_a$? ::
- LSTM ::
- recurrent dropout :: aquel que se hace en las LSTM
- no me queda claro como comparar el one-hot y el embedding :: 
** Notes
- RNN son suceptibles al vanishing gradient
- Las GRU cells alivian el vanishing gradient
- las GRU usan un calculo y segun el valor de la compuerta GU toma el
  valor del estado anterior o el valor calculado
- LSTM reducen efectos de exploding y vanishing gradient
- LSTM guardan información de contexto en las celdas
- 0 olvida 1 actualiza
- la capa de **embedding** reduce la dimensión con respecto a
  **one-hot** en la vectorización del modelo de lenguaje
- sin embargo, embedding requiere un mayor entrenamiento
- Control del Overfitting con Dropout  en las LSTM 
*** Ejercicios
- vocabulary_size 8000
- wordvec_dim 100
- max_tex_len 200
- cargar datos del imdb
- usar pad_sequences seteado a max_tex_len para el padding
- para representar enone hot usar to_categorical(xtrain, vocabulary_size)
- hacer el one-hot tambien para el xtest
** Summary
