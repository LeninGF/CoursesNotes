{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f58154",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.00397,
     "end_time": "2024-11-18T21:09:47.473623",
     "exception": false,
     "start_time": "2024-11-18T21:09:47.469653",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/LeninGF/CoursesNotes/blob/main/InteligenciaArtificalGenerativa/Problems/LSTM-GRU/EjercicioEmbeddingLSTM-GRU-IAG-2024B_LeninFalconi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df781228",
   "metadata": {
    "id": "j_meEkMh7c8P",
    "papermill": {
     "duration": 0.003129,
     "end_time": "2024-11-18T21:09:47.480189",
     "exception": false,
     "start_time": "2024-11-18T21:09:47.477060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RNN Multiclase\n",
    "\n",
    "Coder: Lenin G. Falconí\n",
    "\n",
    "Asignatura: Tópicos Especiales (Inteligencia Artificial)\n",
    "\n",
    "Fecha: 2024-11-18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e228e",
   "metadata": {
    "id": "HjYR2tST8VtQ",
    "papermill": {
     "duration": 0.00307,
     "end_time": "2024-11-18T21:09:47.486515",
     "exception": false,
     "start_time": "2024-11-18T21:09:47.483445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generación de Texto \n",
    "Usando la información presentada, programar el código para la generación de texto basado en las frases de Sheldon para ejecutar en Kaggle. \n",
    "Incluir la preparación de datos, definición del modelo, entrenamiento y generación de texto. Ajustar para mejorar resultados, comparar generación por caracteres vs. Generación por palabras. Probar para otros vocabularios. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eea9738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:47.494943Z",
     "iopub.status.busy": "2024-11-18T21:09:47.494686Z",
     "iopub.status.idle": "2024-11-18T21:09:47.501863Z",
     "shell.execute_reply": "2024-11-18T21:09:47.501063Z"
    },
    "papermill": {
     "duration": 0.012638,
     "end_time": "2024-11-18T21:09:47.503334",
     "exception": false,
     "start_time": "2024-11-18T21:09:47.490696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars_window = 20  # Tamaño de la ventana deslizante\n",
    "step = 3           # Paso para mover la ventana\n",
    "n_epochs = 5      # Número de épocas (ajustable)\n",
    "batch_size = 128   # Tamaño del lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21be66f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:47.511025Z",
     "iopub.status.busy": "2024-11-18T21:09:47.510602Z",
     "iopub.status.idle": "2024-11-18T21:09:59.447754Z",
     "shell.execute_reply": "2024-11-18T21:09:59.446789Z"
    },
    "papermill": {
     "duration": 11.943148,
     "end_time": "2024-11-18T21:09:59.449792",
     "exception": false,
     "start_time": "2024-11-18T21:09:47.506644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.gutenberg.org/files/2000/2000-0.txt\n",
      "\u001b[1m2226045/2226045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "# Load dataset\n",
    "path_to_file = tf.keras.utils.get_file('don_quijote.txt', 'https://www.gutenberg.org/files/2000/2000-0.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# Create a vocabulary\n",
    "vocab = sorted(set(text))\n",
    "char_to_index = {char: index for index, char in enumerate(vocab)}\n",
    "index_to_char = np.array(vocab)\n",
    "\n",
    "# Convert text to integers\n",
    "text_as_int = np.array([char_to_index[char] for char in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2cfc2b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:59.458910Z",
     "iopub.status.busy": "2024-11-18T21:09:59.458423Z",
     "iopub.status.idle": "2024-11-18T21:09:59.464258Z",
     "shell.execute_reply": "2024-11-18T21:09:59.463469Z"
    },
    "papermill": {
     "duration": 0.011882,
     "end_time": "2024-11-18T21:09:59.465756",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.453874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c15555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:59.475281Z",
     "iopub.status.busy": "2024-11-18T21:09:59.475005Z",
     "iopub.status.idle": "2024-11-18T21:09:59.799075Z",
     "shell.execute_reply": "2024-11-18T21:09:59.798172Z"
    },
    "papermill": {
     "duration": 0.331321,
     "end_time": "2024-11-18T21:09:59.800905",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.469584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>next_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139126</th>\n",
       "      <td>e prometido a la pri</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237379</th>\n",
       "      <td>¿Qué lobos os espan</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149585</th>\n",
       "      <td>golpes y brazos, pro</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207959</th>\n",
       "      <td>que no debéis dar cu</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224267</th>\n",
       "      <td>de preguntar qué sig</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sentence next_char\n",
       "139126  e prometido a la pri         n\n",
       "237379   ¿Qué lobos os espan         t\n",
       "149585  golpes y brazos, pro         b\n",
       "207959  que no debéis dar cu         l\n",
       "224267  de preguntar qué sig         n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for sentence in text.split('\\n'):\n",
    "    for i in range(0, len(sentence) - chars_window, step):\n",
    "        sentences.append(sentence[i:i+chars_window])\n",
    "        next_chars.append(sentence[i+chars_window])\n",
    "df = pd.DataFrame({'sentence': sentences, 'next_char':next_chars})\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4e527",
   "metadata": {
    "papermill": {
     "duration": 0.003824,
     "end_time": "2024-11-18T21:09:59.808902",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.805078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2161d0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:59.817835Z",
     "iopub.status.busy": "2024-11-18T21:09:59.817567Z",
     "iopub.status.idle": "2024-11-18T21:09:59.822534Z",
     "shell.execute_reply": "2024-11-18T21:09:59.821778Z"
    },
    "papermill": {
     "duration": 0.011386,
     "end_time": "2024-11-18T21:09:59.824169",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.812783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105,  49,  65])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d57a1fb",
   "metadata": {
    "papermill": {
     "duration": 0.003787,
     "end_time": "2024-11-18T21:09:59.831981",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.828194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542c486b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:09:59.841112Z",
     "iopub.status.busy": "2024-11-18T21:09:59.840871Z",
     "iopub.status.idle": "2024-11-18T21:10:00.758740Z",
     "shell.execute_reply": "2024-11-18T21:10:00.757811Z"
    },
    "papermill": {
     "duration": 0.924916,
     "end_time": "2024-11-18T21:10:00.760857",
     "exception": false,
     "start_time": "2024-11-18T21:09:59.835941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "# Create training examples and targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad24531b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:00.770045Z",
     "iopub.status.busy": "2024-11-18T21:10:00.769803Z",
     "iopub.status.idle": "2024-11-18T21:10:06.154582Z",
     "shell.execute_reply": "2024-11-18T21:10:06.153669Z"
    },
    "papermill": {
     "duration": 5.391648,
     "end_time": "2024-11-18T21:10:06.156664",
     "exception": false,
     "start_time": "2024-11-18T21:10:00.765016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n",
      "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([105,  49,  65,  62,   2,  45,  75,  72,  67,  62,  60,  77,   2,\n",
      "        36,  78,  77,  62,  71,  59,  62,  75,  64,   2,  62,  31,  72,\n",
      "        72,  68,   2,  72,  63,   2,  33,  72,  71,   2,  46,  78,  66,\n",
      "        67,  72,  77,  62,  12,   2,  59,  82,   2,  42,  66,  64,  78,\n",
      "        62,  69,   2,  61,  62,   2,  32,  62,  75,  79,  58,  71,  77,\n",
      "        62,  76,   2,  48,  58,  58,  79,  62,  61,  75,  58,   1,   0,\n",
      "         1,   0,  49,  65,  66,  76,   2,  62,  31,  72,  72,  68,   2,\n",
      "        66,  76,   2,  63,  72,  75,   2,  77,  65])>, <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
      "array([49, 65, 62,  2, 45, 75, 72, 67, 62, 60, 77,  2, 36, 78, 77, 62, 71,\n",
      "       59, 62, 75, 64,  2, 62, 31, 72, 72, 68,  2, 72, 63,  2, 33, 72, 71,\n",
      "        2, 46, 78, 66, 67, 72, 77, 62, 12,  2, 59, 82,  2, 42, 66, 64, 78,\n",
      "       62, 69,  2, 61, 62,  2, 32, 62, 75, 79, 58, 71, 77, 62, 76,  2, 48,\n",
      "       58, 58, 79, 62, 61, 75, 58,  1,  0,  1,  0, 49, 65, 66, 76,  2, 62,\n",
      "       31, 72, 72, 68,  2, 66, 76,  2, 63, 72, 75,  2, 77, 65, 62])>)\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "for i in dataset:\n",
    "    while(cont<10):\n",
    "        print(i)\n",
    "        cont+=1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d2f8717",
   "metadata": {
    "papermill": {
     "duration": 0.004196,
     "end_time": "2024-11-18T21:10:06.165429",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.161233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Crear batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba7218f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:06.175207Z",
     "iopub.status.busy": "2024-11-18T21:10:06.174922Z",
     "iopub.status.idle": "2024-11-18T21:10:06.183035Z",
     "shell.execute_reply": "2024-11-18T21:10:06.182458Z"
    },
    "papermill": {
     "duration": 0.014797,
     "end_time": "2024-11-18T21:10:06.184648",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.169851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9ae13",
   "metadata": {
    "papermill": {
     "duration": 0.003993,
     "end_time": "2024-11-18T21:10:06.192838",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.188845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d890bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:06.202838Z",
     "iopub.status.busy": "2024-11-18T21:10:06.202589Z",
     "iopub.status.idle": "2024-11-18T21:10:06.272263Z",
     "shell.execute_reply": "2024-11-18T21:10:06.271394Z"
    },
    "papermill": {
     "duration": 0.076505,
     "end_time": "2024-11-18T21:10:06.273942",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.197437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, input_shape=(seq_length,)),\n",
    "        LSTM(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'),\n",
    "        Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size=len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc606360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:06.283609Z",
     "iopub.status.busy": "2024-11-18T21:10:06.283328Z",
     "iopub.status.idle": "2024-11-18T21:10:06.298134Z",
     "shell.execute_reply": "2024-11-18T21:10:06.297394Z"
    },
    "papermill": {
     "duration": 0.021345,
     "end_time": "2024-11-18T21:10:06.299763",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.278418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">108,650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m27,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m106\u001b[0m)       │       \u001b[38;5;34m108,650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,382,762</span> (20.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,382,762\u001b[0m (20.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,382,762</span> (20.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,382,762\u001b[0m (20.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efdaf75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:06.309939Z",
     "iopub.status.busy": "2024-11-18T21:10:06.309725Z",
     "iopub.status.idle": "2024-11-18T21:10:06.319888Z",
     "shell.execute_reply": "2024-11-18T21:10:06.319306Z"
    },
    "papermill": {
     "duration": 0.016945,
     "end_time": "2024-11-18T21:10:06.321329",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.304384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5703ac2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:10:06.331497Z",
     "iopub.status.busy": "2024-11-18T21:10:06.331231Z",
     "iopub.status.idle": "2024-11-18T21:14:39.237007Z",
     "shell.execute_reply": "2024-11-18T21:14:39.236101Z"
    },
    "papermill": {
     "duration": 272.913142,
     "end_time": "2024-11-18T21:14:39.239096",
     "exception": false,
     "start_time": "2024-11-18T21:10:06.325954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 65ms/step - loss: 2.5158\n",
      "Epoch 2/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 68ms/step - loss: 1.5839\n",
      "Epoch 3/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 72ms/step - loss: 1.3724\n",
      "Epoch 4/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 78ms/step - loss: 1.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 81ms/step - loss: 1.2218\n",
      "Epoch 6/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - loss: 1.1842\n",
      "Epoch 7/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 79ms/step - loss: 1.1424\n",
      "Epoch 8/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 81ms/step - loss: 1.1143\n",
      "Epoch 9/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - loss: 1.0881\n",
      "Epoch 10/10\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 80ms/step - loss: 1.0596\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3951dbf4",
   "metadata": {
    "papermill": {
     "duration": 0.154072,
     "end_time": "2024-11-18T21:14:39.546860",
     "exception": false,
     "start_time": "2024-11-18T21:14:39.392788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generar Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc70d5e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:14:39.850137Z",
     "iopub.status.busy": "2024-11-18T21:14:39.849812Z",
     "iopub.status.idle": "2024-11-18T21:14:39.856332Z",
     "shell.execute_reply": "2024-11-18T21:14:39.855546Z"
    },
    "papermill": {
     "duration": 0.159858,
     "end_time": "2024-11-18T21:14:39.858073",
     "exception": false,
     "start_time": "2024-11-18T21:14:39.698215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate=10, temperature=1.0):\n",
    "    num_generate = num_generate\n",
    "    input_eval = [char_to_index[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = temperature\n",
    "\n",
    "#     model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(index_to_char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14479e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T21:14:40.158882Z",
     "iopub.status.busy": "2024-11-18T21:14:40.158572Z",
     "iopub.status.idle": "2024-11-18T21:14:42.169476Z",
     "shell.execute_reply": "2024-11-18T21:14:42.168429Z"
    },
    "papermill": {
     "duration": 2.163218,
     "end_time": "2024-11-18T21:14:42.171253",
     "exception": false,
     "start_time": "2024-11-18T21:14:40.008035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panza, como vas? llvichetos os uijeseratadelioncimardiamo ra dire\r\n",
      "y Esterestodió sente es múndo dene tues leltaselore rtos mie len y frosas e suedentaño ala, Cila aral comaren bierns; tija quengó pizóncale, da edong\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=\"panza, como vas?\", temperature=1, num_generate=200))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 119408755,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 299.73746,
   "end_time": "2024-11-18T21:14:44.817101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T21:09:45.079641",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
